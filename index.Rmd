---
title: "Practical Machine Learning Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(doMC)
setwd("~/Dropbox (fresh4cast)/Learn/ML in R/project/ML-project")
```

## Question
Can we predict the manner in which people lift barbells, using the data from sensors on their belt, arm, forearm and on the dumbell itself?


## Feature selection
The dataset contains 19622 observations of 160 variables. The objective is to predict "classe". After inspecting the variables using str(dt) we first exclude the columns that are not relevant, and variables with incomplete measurements. Then split the dataset into training and testing sets. 
* Note:
Each person is likely to make the movements in a slightly different way. So if we use the name in the model (by turning it into 6 indicator variables) we will probably get a better fit. But that model would not generalise as well.

```{r data, warning = FALSE, cache=TRUE}
dt = read.csv("pml-training.csv", na.strings=c("","NA"))
tt = read.csv("pml-testing.csv", na.strings=c("","NA"))
dts = dt[,c(8:160)]

dts = dts[,apply(dts, 2, function(x) !any(is.na(x)))]
inTrain <- createDataPartition(y=dts$classe, p=6/10, list=FALSE)
trn <- dts[inTrain,]
tst <- dts[-inTrain,]
summary(complete.cases(trn))


```


## Model selection
Three classification methods were tried: Recursive Partitioning and Regression Trees, Random Forrest and Boosting. Random Forrest and Boosting had significantly higher accuracy than rpart. The cross-validation parameters were fine-tuned to improve accuracy further. Random Forrest and Boosting worked well with 5 folds repeated 3 times. Only marginal improvements were obtained with more folds or repetitions. 


```{r train_with_cross-validation, warning = FALSE, cache=TRUE}
set.seed(3223)
registerDoMC(cores = 7)

model_rp <- train(classe ~ ., data=trn, method="rpart", trControl=trainControl(method="repeatedcv", number=5, repeats = 3))

model_rf <- train(classe ~ ., data=trn, method="rf", trControl=trainControl(method="repeatedcv", number=5, repeats = 3))

model_bs <- train(classe ~ ., data=trn, method="gbm", verbose=FALSE, trControl=trainControl(method="repeatedcv", number=5, repeats = 3))

confusionMatrix(model_rp)
confusionMatrix(model_rf)
confusionMatrix(model_bs)
```


## Out of sample error
The three models are tested for out-of-sample error. Random Forrest performs best, with less than 0.5% error.

```{r testing, warning = FALSE, cache=TRUE}
confusionMatrix(predict(model_rp, tst), tst$classe)
confusionMatrix(predict(model_rf, tst), tst$classe)
confusionMatrix(predict(model_bs, tst), tst$classe)

```


## Summary and Conclusion
The manner in which people lift barbells can be predicted from the measurements available with an estimated error rate significantly below 1%. 


```{r final_model, warning = FALSE, cache=TRUE}
plot(model_rf$finalModel, main="Accuracy of final model")
tts = tt[,c(8:160)]
tts = tts[,apply(tts, 2, function(x) !any(is.na(x)))]
# predict(model_rf, tts)
```

